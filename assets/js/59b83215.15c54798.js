"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[603],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>h});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function p(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?p(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):p(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},p=Object.keys(e);for(a=0;a<p.length;a++)n=p[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var p=Object.getOwnPropertySymbols(e);for(a=0;a<p.length;a++)n=p[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var i=a.createContext({}),l=function(e){var t=a.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=l(e.components);return a.createElement(i.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,p=e.originalType,i=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),m=l(n),d=r,h=m["".concat(i,".").concat(d)]||m[d]||u[d]||p;return n?a.createElement(h,o(o({ref:t},c),{},{components:n})):a.createElement(h,o({ref:t},c))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var p=n.length,o=new Array(p);o[0]=d;var s={};for(var i in t)hasOwnProperty.call(t,i)&&(s[i]=t[i]);s.originalType=e,s[m]="string"==typeof e?e:r,o[1]=s;for(var l=2;l<p;l++)o[l]=n[l];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},4684:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>o,default:()=>u,frontMatter:()=>p,metadata:()=>s,toc:()=>l});var a=n(7462),r=(n(7294),n(3905));const p={},o="Apps",s={unversionedId:"guides/apps",id:"guides/apps",title:"Apps",description:"Warning: this is an experimental feature and is subject to change.",source:"@site/docs/guides/apps.md",sourceDirName:"guides",slug:"/guides/apps",permalink:"/promptz/guides/apps",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Guides",permalink:"/promptz/category/guides"},next:{title:"Config",permalink:"/promptz/guides/config"}},i={},l=[{value:"Setup",id:"setup",level:2},{value:"Prompts",id:"prompts",level:2},{value:"Admin",id:"admin",level:2},{value:"Notebooks",id:"notebooks",level:2},{value:"Systems",id:"systems",level:2}],c={toc:l},m="wrapper";function u(e){let{components:t,...p}=e;return(0,r.kt)(m,(0,a.Z)({},c,p,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"apps"},"Apps"),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},(0,r.kt)("em",{parentName:"p"},"Warning: this is an experimental feature and is subject to change."))),(0,r.kt)("p",null,"You can use ",(0,r.kt)("strong",{parentName:"p"},"promptz")," as a library or a framework. For simple use cases, or integrating into existing codebase, library usage is the way to go. But, if you're starting a new project or want to centralize LLM access via an API, creating an app provides a quick way to get started by generating an API, admin interface, and cli for you to interact with your prompts and collections."),(0,r.kt)("h2",{id:"setup"},"Setup"),(0,r.kt)("p",null,"Let's create a new app:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pz create my-app\ncd my-app\n")),(0,r.kt)("p",null,"This will create a new directory called ",(0,r.kt)("inlineCode",{parentName:"p"},"my-app")," with the following structure:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"my-app\n\u251c\u2500\u2500 admin\n\u251c\u2500\u2500 notebooks\n\u251c\u2500\u2500 prompts\n\u251c\u2500\u2500 systems\n\u251c\u2500\u2500 app.py\n\u251c\u2500\u2500 README.md\n")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"app.py")," file is the entry point of your app and is where you can configure settings like LLMs, databases, etc. Here's what the generated ",(0,r.kt)("inlineCode",{parentName:"p"},"app.py")," looks like:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from promptz import App\n\ndef create_app():\n    app = App()\n    return app\n\nif __name__ == "__main__":\n    app = create_app()\n    app.serve()\n')),(0,r.kt)("p",null,"This is the bare minimum to get your app running using a mock LLM. Let's run it:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"python app.py\n")),(0,r.kt)("p",null,"This does a few things. First, it loads all prompts, notebooks, systems, and admin pages from the relevant directories (we'll go through what each of these mean below). Then it starts a FastAPI server and Dash admin app - by default these are available at ",(0,r.kt)("inlineCode",{parentName:"p"},"http://localhost:8000")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"http://localhost:8001")," respectively."),(0,r.kt)("p",null,"We can test that everything is working by calling the prompt API:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl -X POST http://localhost:8000/api/prompt -d '{\"input\": \"What is the capital of France?\"}'\n>>> 'This is a mock response'\n")),(0,r.kt)("p",null,"The API is working, but because we haven't configured an LLM it will default to the mock LLM. Let's setup ChatGPT by adding the following to ",(0,r.kt)("inlineCode",{parentName:"p"},"app.py"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import os\nfrom promptz import App, ChatGPT\n\nllm = ChatGPT(\n    api_key=os.getenv('OPENAI_API_KEY'),\n    org_id=os.getenv('OPENAI_ORG_ID'),\n)\n\ndef create_app():\n    app = App(llm=llm)\n    return app\n\nif __name__ == \"__main__\":\n    app = create_app()\n    app.serve()\n")),(0,r.kt)("p",null,"Now, if we curl the API again we should get a response from ChatGPT:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl -X POST http://localhost:8000/prompts -d '{\"input\": \"What is the capital of France?\"}'\n>>> 'The capital of France is Paris.'\n")),(0,r.kt)("h2",{id:"prompts"},"Prompts"),(0,r.kt)("p",null,"This can be useful as a way to centralize access to LLMs across an organization, but you can also create predefined prompts that can then be triggered from the API. Let's create a new prompt by adding a JSON file to the ",(0,r.kt)("inlineCode",{parentName:"p"},"/prompts")," directory:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "name": "qa",\n    "instructions": "Answer the question with a factual answer.",\n    "examples": [\n        {\n            "input": "What is the capital of France?",\n            "output": "Paris"\n        }\n    ],\n}\n')),(0,r.kt)("p",null,"Now, once we restart the app to load the new prompt, we can trigger the stored prompt from the API:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl -X POST http://localhost:8000/prompts/qa/run -d '{\"input\": \"What is the capital of Germany?\"}'\n>>> 'Berlin'\n")),(0,r.kt)("p",null,"You can also trigger prompts from the cli:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pz prompts run qa \"What is the capital of Germany?\"\n>>> 'Berlin'\n")),(0,r.kt)("h2",{id:"admin"},"Admin"),(0,r.kt)("p",null,"Next, let's look at the admin interface. By default, admin pages are created for prompts, notebooks, systems, and collections using the ",(0,r.kt)("strong",{parentName:"p"},"Dash")," framework. If you navigate to ",(0,r.kt)("inlineCode",{parentName:"p"},"http://localhost:8001/prompts")," you'll see a list of all the prompts that you have created. Click on the ",(0,r.kt)("inlineCode",{parentName:"p"},"qa")," prompt and you'll see something like:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"prompt admin",src:n(954).Z,width:"1198",height:"596"})),(0,r.kt)("p",null,"Currently, you can only update prompts in code, but you can trigger them and see a log of past results from the admin page."),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"The admin interface is still in a very early stage of development. Prompts and notebooks are the only things that are currently supported, but we plan to add support for systems and collections soon as well as support for custom admin pages.")),(0,r.kt)("h2",{id:"notebooks"},"Notebooks"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Notebooks")," are loaded from the ",(0,r.kt)("inlineCode",{parentName:"p"},"/notebooks")," directory and can be viewed from the admin interface. They are rendered as html using ",(0,r.kt)("inlineCode",{parentName:"p"},"nbconvert")," and provide a simple way to share experiments, reports, etc. with others."),(0,r.kt)("p",null,"To initialize a notebook with the current state of the app, you can import the ",(0,r.kt)("inlineCode",{parentName:"p"},"create_app")," function from ",(0,r.kt)("inlineCode",{parentName:"p"},"app.py")," and use it to create a new ",(0,r.kt)("strong",{parentName:"p"},"session"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from ../app import create_app\n\napp = create_app()\nsession = app.world.create_session()\n\nsession.prompt('What is the capital of France?')\n>>> 'Paris'\n")),(0,r.kt)("p",null,"Alternatively, you can set the default session, which will bind the top-level helpers to it:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from promptz import set_default_session\n\nset_default_session(session)\nprompt('What is the capital of France?')\n>>> 'Paris'\n")),(0,r.kt)("h2",{id:"systems"},"Systems"),(0,r.kt)("p",null,"The structure of ",(0,r.kt)("strong",{parentName:"p"},"Apps")," are inspired by ",(0,r.kt)("strong",{parentName:"p"},"entity-component-systems")," from game development, where the stored embeddings act as the entities/components. ",(0,r.kt)("strong",{parentName:"p"},"Systems")," let you define some transformation logic on stored entities, much like you would define models to update data in ",(0,r.kt)("strong",{parentName:"p"},"dbt"),"."),(0,r.kt)("p",null,"Here's a simple example that updates the age of all villain characters:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from promptz import System\n\nclass UpdateAge(System):\n    query = Query(\n        'they are a villain',\n        where={'type': 'character'}\n    )\n\n    def process(self, entities):\n        entities['age'] = entities['age'] + 1\n        return entities\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Systems")," are loaded into the app from the ",(0,r.kt)("inlineCode",{parentName:"p"},"/systems")," directory. To run all systems, you can call the app's world instance with a session:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"session = app.world.create_session()\napp.world(session)\n")),(0,r.kt)("p",null,"Or call this from the API or cli:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl -X POST http://localhost:8000/systems/run\n\n# cli usage\npz systems run\n")),(0,r.kt)("p",null,"This will run all systems in the order defined. Support for running individual systems and subsets of systems is will be added soon."))}u.isMDXComponent=!0},954:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/prompts-admin-df000aea5b62fcd00523d3b34c97c8f0.png"}}]);