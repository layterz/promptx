{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# promptx\n",
    "\n",
    "A framework for building AI systems.\n",
    "\n",
    "```bash\n",
    "pip install pxx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 08:38:50.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpromptx\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mloading local app from /home/rjl/promptx\u001b[0m\n",
      "\u001b[32m2023-11-01 08:38:50.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpromptx\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mloaded environment variables from /home/rjl/promptx/.env\u001b[0m\n",
      "\u001b[32m2023-11-01 08:38:50.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpromptx\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mAPI KEY wMeGC\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ChatGPT.__init__() missing 2 required positional arguments: 'api_key' and 'org_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rjl/promptx/getting-started.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/rjl/promptx/getting-started.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpromptx\u001b[39;00m \u001b[39mimport\u001b[39;00m prompt\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/rjl/promptx/getting-started.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m character \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mBatman\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/rjl/promptx/getting-started.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m prompt(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mWrite a character profile for \u001b[39;49m\u001b[39m{\u001b[39;49;00mcharacter\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/promptx/promptx/__init__.py:30\u001b[0m, in \u001b[0;36mprompt\u001b[0;34m(instructions, input, output, prompt, context, template, llm, examples, allow_none, history, tools, dryrun, retries, debug, silent, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprompt\u001b[39m(instructions\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, prompt\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, template\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, llm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, examples\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allow_none\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, history\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tools\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dryrun\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, retries\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, debug\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, silent\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m     14\u001b[0m         instructions\u001b[39m=\u001b[39minstructions,\n\u001b[1;32m     15\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m         retries\u001b[39m=\u001b[39mretries,\n\u001b[1;32m     29\u001b[0m     )\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mreturn\u001b[39;00m DEFAULT_SESSION\u001b[39m.\u001b[39;49mprompt(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/promptx/promptx/world.py:83\u001b[0m, in \u001b[0;36mSession.prompt\u001b[0;34m(self, instructions, input, output, id, context, template, llm, examples, allow_none, logs, tools, dryrun, retries, debug, silent, to_json, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery(ids\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m], collection\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m         llm \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mfirst\n\u001b[1;32m     84\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(llm, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     85\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery(ids\u001b[39m=\u001b[39m[llm], collection\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/promptx/promptx/collection.py:755\u001b[0m, in \u001b[0;36mCollection.first\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    754\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfirst\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 755\u001b[0m     objects \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjects\n\u001b[1;32m    756\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objects) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    757\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/promptx/promptx/collection.py:730\u001b[0m, in \u001b[0;36mCollection.objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m     m \u001b[39m=\u001b[39m {\u001b[39mid\u001b[39m: metadata \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m, metadata \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(d[\u001b[39m'\u001b[39m\u001b[39mids\u001b[39m\u001b[39m'\u001b[39m], d[\u001b[39m'\u001b[39m\u001b[39mmetadatas\u001b[39m\u001b[39m'\u001b[39m])}\n\u001b[1;32m    726\u001b[0m     schemas \u001b[39m=\u001b[39m {\n\u001b[1;32m    727\u001b[0m         \u001b[39mid\u001b[39m: json\u001b[39m.\u001b[39mloads(metadata[\u001b[39m'\u001b[39m\u001b[39mschema\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m, metadata \u001b[39min\u001b[39;00m m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    728\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mschema\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m metadata \u001b[39mand\u001b[39;00m metadata[\u001b[39m'\u001b[39m\u001b[39mschema\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    729\u001b[0m     }\n\u001b[0;32m--> 730\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    731\u001b[0m         create_entity_from_schema(\n\u001b[1;32m    732\u001b[0m             schemas\u001b[39m.\u001b[39mget(r[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m    733\u001b[0m             {\n\u001b[1;32m    734\u001b[0m                 k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(v) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, \u001b[39mlist\u001b[39m) \u001b[39melse\u001b[39;00m pd\u001b[39m.\u001b[39mnotnull(v))\n\u001b[1;32m    735\u001b[0m             },\n\u001b[1;32m    736\u001b[0m             session\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession,\n\u001b[1;32m    737\u001b[0m             base\u001b[39m=\u001b[39mREGISTERED_ENTITIES\u001b[39m.\u001b[39mget(r[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m], Entity),\n\u001b[1;32m    738\u001b[0m         ) \n\u001b[1;32m    739\u001b[0m         \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dict(\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    740\u001b[0m     ]\n\u001b[1;32m    741\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    743\u001b[0m         create_entity_from_schema(\n\u001b[1;32m    744\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema \u001b[39mor\u001b[39;00m {},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dict(\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    751\u001b[0m     ]\n",
      "File \u001b[0;32m~/promptx/promptx/collection.py:731\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    725\u001b[0m     m \u001b[39m=\u001b[39m {\u001b[39mid\u001b[39m: metadata \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m, metadata \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(d[\u001b[39m'\u001b[39m\u001b[39mids\u001b[39m\u001b[39m'\u001b[39m], d[\u001b[39m'\u001b[39m\u001b[39mmetadatas\u001b[39m\u001b[39m'\u001b[39m])}\n\u001b[1;32m    726\u001b[0m     schemas \u001b[39m=\u001b[39m {\n\u001b[1;32m    727\u001b[0m         \u001b[39mid\u001b[39m: json\u001b[39m.\u001b[39mloads(metadata[\u001b[39m'\u001b[39m\u001b[39mschema\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m, metadata \u001b[39min\u001b[39;00m m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    728\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mschema\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m metadata \u001b[39mand\u001b[39;00m metadata[\u001b[39m'\u001b[39m\u001b[39mschema\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    729\u001b[0m     }\n\u001b[1;32m    730\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m--> 731\u001b[0m         create_entity_from_schema(\n\u001b[1;32m    732\u001b[0m             schemas\u001b[39m.\u001b[39;49mget(r[\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[1;32m    733\u001b[0m             {\n\u001b[1;32m    734\u001b[0m                 k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m r\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m (\u001b[39mlen\u001b[39;49m(v) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(v, \u001b[39mlist\u001b[39;49m) \u001b[39melse\u001b[39;49;00m pd\u001b[39m.\u001b[39;49mnotnull(v))\n\u001b[1;32m    735\u001b[0m             },\n\u001b[1;32m    736\u001b[0m             session\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession,\n\u001b[1;32m    737\u001b[0m             base\u001b[39m=\u001b[39;49mREGISTERED_ENTITIES\u001b[39m.\u001b[39;49mget(r[\u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m], Entity),\n\u001b[1;32m    738\u001b[0m         ) \n\u001b[1;32m    739\u001b[0m         \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dict(\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    740\u001b[0m     ]\n\u001b[1;32m    741\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    743\u001b[0m         create_entity_from_schema(\n\u001b[1;32m    744\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema \u001b[39mor\u001b[39;00m {},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dict(\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    751\u001b[0m     ]\n",
      "File \u001b[0;32m~/promptx/promptx/collection.py:330\u001b[0m, in \u001b[0;36mcreate_entity_from_schema\u001b[0;34m(schema, data, session, base)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[39mreturn\u001b[39;00m [m\u001b[39m.\u001b[39mload(session\u001b[39m=\u001b[39msession, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefaults, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mo}) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m data]\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m     \u001b[39mreturn\u001b[39;00m m\u001b[39m.\u001b[39;49mload(session\u001b[39m=\u001b[39;49msession, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdefaults, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata})\n",
      "File \u001b[0;32m~/promptx/promptx/collection.py:383\u001b[0m, in \u001b[0;36mEntity.load\u001b[0;34m(cls, session, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    381\u001b[0m         \u001b[39msetattr\u001b[39m(\u001b[39mcls\u001b[39m, name, \u001b[39mproperty\u001b[39m(loader))\n\u001b[0;32m--> 383\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: ChatGPT.__init__() missing 2 required positional arguments: 'api_key' and 'org_id'"
     ]
    }
   ],
   "source": [
    "from promptx import prompt\n",
    "\n",
    "character = 'Batman'\n",
    "prompt(f'Write a character profile for {character}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this returns a plain string response, but to generate complex data you can pass in the expected schema along with the prompt input.\n",
    "\n",
    "*Note: `Entity` is a thin layer on top of `pydantic.BaseModel` that allows the object to be stored as an embedding. You can use `pydantic.BaseModel` directly if you don't need to store the object as an embedding and just want to use it as the prompt output schema.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field\n",
    "from promptx.collection import Entity\n",
    "\n",
    "class Character(Entity):\n",
    "    name: str = Field(..., embed=False),\n",
    "    description: str = Field(..., description='Describe the character in a few sentences')\n",
    "    age: int = Field(..., ge=0, le=120)\n",
    "\n",
    "batman = prompt('Generate a character profile for Batman', output=Character)\n",
    "batman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns an instance of the specified schema using the generated response as the input data. Let's create a list of instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = prompt(\n",
    "    'Generate some characters from the Batman universe',\n",
    "    output=[Character],\n",
    ")\n",
    "\n",
    "characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output is a list, `prompt` returns a `Collection`, which extends `pd.DataFrame`. To extract the `Entity` representations, use the `objects` property.\n",
    "\n",
    "We can now store these generated objects as embeddings in a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptx import store\n",
    "\n",
    "store(*characters.objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stores the object as an embedding, along with some metadata, in a vector database (ChromaDB by default). The process is quite simple, it embeds the whole object as a JSON string and each field individually. This allows us to query the database using any field in the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptx import query\n",
    "\n",
    "query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate some more characters and add them to the collection. We'll first get any existing characters and extract their names, which we can pass to the prompt to avoid generating duplicates. Any characters generated will be added the list during iteration. Finally, we'll store all the generated characters in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "characters = query().objects\n",
    "\n",
    "for _ in range(n):\n",
    "    characters += prompt(\n",
    "        '''\n",
    "        Generate a list of new characters from the Batman universe.\n",
    "        Don't use any of the existing characters.\n",
    "        ''',\n",
    "        input = {\n",
    "            'existing_characters': [c.name for c in characters],\n",
    "        },\n",
    "        output=[Character],\n",
    "    ).objects\n",
    "\n",
    "store(*characters)\n",
    "query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the characters are embedded, we can query the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "villains = query('they are a villain')\n",
    "villains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This compares the query text with the stored objects, returning results that are closest in vector space.\n",
    "\n",
    "*Note: the effectiveness of embedding queries will depend on what data has been embedded. In this case, ChatGPT will know some details about the generated characters and so does a decent job on this data. For other data, you may find generating synthetic intermediary data to be helpful. E.g. generating `thoughts` and/or `quotes` about a set of documents.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `Collection` extends `pd.DataFrame`, we can use all the usual Pandas methods to filter and sort the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "villains[villains.age < 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationships can be defined by setting the field to a type which subclasses `Entity` (or a list of that type). Internally, this is stored as a query and then loaded when the field is accessed from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryIdea(Entity):\n",
    "    title: str\n",
    "    description: str = None\n",
    "    characters: list[Character] = None\n",
    "\n",
    "characters = query('they are a villain').sample(3).objects\n",
    "\n",
    "ideas = prompt(\n",
    "    'Generate some story ideas',\n",
    "    input={\n",
    "        'characters': characters,\n",
    "    },\n",
    "    output=[StoryIdea],\n",
    ").objects\n",
    "\n",
    "for idea in ideas:\n",
    "    idea.characters = characters\n",
    "\n",
    "store(*ideas, collection='story-ideas')\n",
    "query(collection='story-ideas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output is being stored in a collection called `story-ideas`, which is created if it doesn't exist. Previously, all the data we've stored has been in the 'default' collection.\n",
    "\n",
    "*Collections are widely used internally to represent stored models, templates, prompt history, etc. This provides a consistent interface for accessing and manipulating data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've used the default model (GPT-3.5) when generating data, but you can specify a custom model using the `llm=` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptx.models.openai import ChatGPT\n",
    "\n",
    "gpt4 = ChatGPT(id='gpt4', model='gpt4')\n",
    "\n",
    "characters = prompt(\n",
    "    'Generate some characters from the Batman universe',\n",
    "    output=[Character],\n",
    "    llm=gpt4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define any commonly used models, templates, etc, along with defining other settings, by creating a `config.py` file in the root of the project (i.e. adjacent to the `.px/` directory). This file is loaded when the project is initialized and a `setup` function is expected. Here's a simple example that defines a few custom models and a template.\n",
    "\n",
    "```\n",
    "# ./config.py\n",
    "\n",
    "from promptx.models.openai import ChatGPT\n",
    "\n",
    "gpt4 = ChatGPT(id='gpt4', model='gpt4')\n",
    "\n",
    "def setup(session):\n",
    "    session.store(gpt4, collection='models')\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
