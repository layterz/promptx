{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arxiv reader\n",
    "\n",
    "This example demonstrates a technique for generating understanding over long documents - papers from the latest arxiv papers in the AI category in this case.\n",
    "\n",
    "The basic approach is to iterate over the document in chunks and ask the LLM to generate a synthetic dataset of thoughts about each chunk. The thoughts and the chunk are then embedded and can be recalled in subsequent iterations by querying the collection. Then we'll use the generated thoughts to ask questions about the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define the data types that we'll be generating. Because we're embedding the generated objects we're using `Entity`, which is a thin wrapper on top of `pydantic.BaseModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-10 08:10:57.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpromptx\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mloading local app from /home/rjl/promptx/examples/arxiv-reader\u001b[0m\n",
      "\u001b[32m2023-11-10 08:10:57.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpromptx\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mloaded environment variables from /home/rjl/promptx/examples/arxiv-reader/.env\u001b[0m\n",
      "\u001b[32m2023-11-10 08:10:57.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpromptx\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mAPI KEY wMeGC\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from pydantic import Field\n",
    "from promptx.collection import Entity\n",
    "\n",
    "\n",
    "class Document(Entity):\n",
    "    title: str\n",
    "    abstract: str\n",
    "    url: str\n",
    "\n",
    "class Quote(Entity):\n",
    "    value: str\n",
    "    source: Document = None\n",
    "    start: int = None\n",
    "    end: int = None\n",
    "\n",
    "class ThoughtCategory(str, Enum):\n",
    "    fact = 'fact'\n",
    "    opinion = 'opinion'\n",
    "    idea = 'idea'\n",
    "    connection = 'connection'\n",
    "    belief = 'belief'\n",
    "\n",
    "class Thought(Entity):\n",
    "    value: str\n",
    "    category: ThoughtCategory\n",
    "    confidence: float\n",
    "    source: Entity = Field(None, generate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to get the data from arxiv. We'll use `requests` to get the data ans `BeautifulSoup` to parse it into a `Document` instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use these functions to fetch the latest papers, select one at random, and extract the data from the HTML content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document instance only has data about the paper and doesn't contain the actual text. Let's create a function to extract text from a PDF given a path or URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "def load_pdf(filepath_or_url):\n",
    "    \"\"\"\n",
    "    Load content of a PDF from either a file path or a remote URL.\n",
    "    \n",
    "    :param filepath_or_url: File path or URL to fetch the PDF from.\n",
    "    :return: Content of the PDF as a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle remote URL\n",
    "    if filepath_or_url.startswith((\"http://\", \"https://\")):\n",
    "        response = requests.get(filepath_or_url)\n",
    "        response.raise_for_status()\n",
    "        id = str(uuid.uuid4())\n",
    "        filepath_or_url = f'./data/{id}.pdf'\n",
    "        with open(filepath_or_url, 'wb') as pdf:\n",
    "            pdf.write(response.content)\n",
    "    \n",
    "    with open(filepath_or_url, 'rb') as f:\n",
    "        pdf_reader = PyPDF2.PdfReader(f)\n",
    "        text_content = ''.join([page.extract_text() for page in pdf_reader.pages])\n",
    "    return text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "pdf = load_pdf('./data/8c2d8faa-e281-4378-86e8-8b9ff23c0921.pdf')\n",
    "doc = nlp(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the full text, but how do we split it into chunks that are small enough to be processed by the LLM? You could do this in a number of ways, but we'll use `spacy`, a popular NLP library, to split the text into sentences and then group them into chunks of 512 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a parsed `spacy` document we can split it into sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could iterate over each sentence individually, but that will be slow, expensive, and some sentences will be too short to convery meaning on their own. Instead, we'll group them into batches, or passages, and generate thoughts based on each passage of text. Before we do that, let's define a helper function to process the sentences in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(generator, bs=1, limit=100):\n",
    "    b = []\n",
    "    i = 0\n",
    "    for item in generator:\n",
    "        if limit and i > limit:\n",
    "            break\n",
    "        b.append(item)\n",
    "        if len(b) == bs:\n",
    "            yield b\n",
    "            b = []\n",
    "        i += bs\n",
    "    if b and (limit and i <= limit):  # Yield any remaining items in the batch\n",
    "        yield b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function yield's the generator in chunks defines by the batch size up to a total number of processed items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DAIL:, Data Augmentation for In-Context Learning via Self-Paraphrase\n",
      "Dawei Li, Yaxuan Li, Dheeraj Mekala, Shuyao Li,\n",
      "Yulin wang, Xueqi Wang, William Hogan, Jingbo Shang\n",
      "University of California, San Diego\n",
      "dal034, yal105, dmekala, shl118, yuw033\n",
      "xuw030, whogan, jshang@ucsd.edu\n",
      "Abstract\n",
      "In-Context Learning (ICL) combined with pre-\n",
      "trained large language models has achieved\n",
      "promising results on various NLP tasks., How-\n",
      "ever, ICL requires high-quality annotated\n",
      "demonstrations which might not be available\n",
      "in real-world scenarios., To overcome this limi-\n",
      "tation, we propose DataAugmentation for In-\n",
      "Context Learning ( DAIL )., DAIL leverages the\n",
      "intuition that large language models are more\n",
      "familiar with the content generated by them-\n",
      "selves.]\n",
      "[It first utilizes the language model to\n",
      "generate paraphrases of the test sample and\n",
      "employs majority voting to determine the final\n",
      "result based on individual predictions., Our ex-\n",
      "tensive empirical evaluation shows that DAIL\n",
      "outperforms the standard ICL method and other\n",
      "ensemble-based methods in the low-resource\n",
      "scenario., Additionally, we explore the use of\n",
      "voting consistency as a confidence score of the\n",
      "model when the logits of predictions are inac-\n",
      "cessible., We believe our work will stimulate\n",
      "further research on ICL in low-resource set-\n",
      "tings.\n",
      ", 1 Introduction\n",
      "Recently, the rapid development of large language\n",
      "models (LLMs) (Devlin et al., 2018; Radford et al.,\n",
      "2019) and their striking skill and knowledge have\n",
      "sparked significant interest in In-Context Learning\n",
      "(ICL) (Brown et al., 2020).]\n",
      "[Different from other\n",
      "training-based paradigms, under ICL, there is no\n",
      "parameter adjustment to LLMs., Instead, the model\n",
      "is given an instruction, which usually consists of\n",
      "a task description (or prompt), several in-context\n",
      "samples (or demonstration), and the test case that\n",
      "needs to be inferred., This tuning-free approach has\n",
      "gained prominence in various research domains\n",
      "within Natural Language Processing (NLP) due\n",
      "to its impressive performance in numerous down-\n",
      "stream tasks (Bonifacio et al., 2022; Gao et al.,\n",
      "2023b,a).ICL requires demonstrations as part of the con-\n",
      "text., Many works focus on improving ICL by em-\n",
      "ploying diverse methods to select suitable demon-\n",
      "strations, such as similarity-based retrieval (Liu\n",
      "et al., 2021; Rubin et al., 2021), score func-\n",
      "tion learning (Li and Qiu, 2023), permutation\n",
      "search (Lu et al., 2021; Wu et al., 2022), and etc.\n",
      ", However, in numerous real-world scenarios, the\n",
      "availability of annotated samples is severely con-\n",
      "strained (Mekala and Shang, 2020; Su et al., 2022)\n",
      "for such demonstration selection.]\n",
      "[Moreover, in the\n",
      "fine-grained classification with a large target-label\n",
      "space, the context length of LLMs could not accom-\n",
      "modate more than one demonstration per label.\n",
      ", To address these problems, we leverage the in-\n",
      "sight of using the ensemble method and improve\n",
      "ICL for low-resource scenarios., We propose Data\n",
      "Augmentation for In-Context Learning ( DAIL )\n",
      "that uses the large language model paraphrase the\n",
      "test sample multiple times., Subsequently, the para-\n",
      "phrased samples, along with the original test sam-\n",
      "ple, are separately presented to the large language\n",
      "model for inference., Finally, a majority voting\n",
      "mechanism is employed to integrate all the single\n",
      "results and get the final label.]\n"
     ]
    }
   ],
   "source": [
    "for chunk in batch(doc.sents, bs=5, limit=100):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptx import delete_collection\n",
    "\n",
    "try:\n",
    "    delete_collection('tmp-quotes')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptx import store\n",
    "\n",
    "def store_quotes(doc: list[str], bs=5, limit=None, collection='tmp'):\n",
    "    for chunk in batch(doc, bs=bs, limit=limit):\n",
    "        quotes = [Quote(value=line) for line in chunk]\n",
    "        store(*quotes, collection=collection)\n",
    "\n",
    "store_quotes([sentence.text for sentence in doc.sents], bs=10, collection='tmp-quotes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the logic for thought generation. It's often tempting to overcomplicate prompts, but it can be difficult to know whether more information is actually helping. Often, less is more as it allows the model to focus more effectively.\n",
    "\n",
    "Let's start by simply generating a list of thoughts based on the current passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptx import prompt\n",
    "\n",
    "def read(doc: list[str], bs=5, limit=None):\n",
    "    thoughts = []\n",
    "    for chunk in batch(doc, bs=bs, limit=limit):\n",
    "        print(f'Passage: {chunk}')\n",
    "        output = prompt(\n",
    "            '''\n",
    "            Given a passage from a document, generate a list of thoughts about the passage.\n",
    "            ''',\n",
    "            input=dict(\n",
    "                passage=chunk,\n",
    "            ),\n",
    "            output=[Thought],\n",
    "        ).objects\n",
    "\n",
    "        print(f'Thoughts: {[t.value for t in output]}')\n",
    "        thoughts += output\n",
    "    return thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage: ['DAIL:', 'Data Augmentation for In-Context Learning via Self-Paraphrase\\nDawei Li, Yaxuan Li, Dheeraj Mekala, Shuyao Li,\\nYulin wang, Xueqi Wang, William Hogan, Jingbo Shang\\nUniversity of California, San Diego\\ndal034, yal105, dmekala, shl118, yuw033\\nxuw030, whogan, jshang@ucsd.edu\\nAbstract\\nIn-Context Learning (ICL) combined with pre-\\ntrained large language models has achieved\\npromising results on various NLP tasks.', 'How-\\never, ICL requires high-quality annotated\\ndemonstrations which might not be available\\nin real-world scenarios.', 'To overcome this limi-\\ntation, we propose DataAugmentation for In-\\nContext Learning ( DAIL ).', 'DAIL leverages the\\nintuition that large language models are more\\nfamiliar with the content generated by them-\\nselves.']\n",
      "Thoughts: ['Data Augmentation for In-Context Learning via Self-Paraphrase', 'ICL requires high-quality annotated demonstrations', 'DataAugmentation for In-Context Learning ( DAIL )', 'Large language models are more familiar with the content generated by themselves']\n",
      "Passage: ['It first utilizes the language model to\\ngenerate paraphrases of the test sample and\\nemploys majority voting to determine the final\\nresult based on individual predictions.', 'Our ex-\\ntensive empirical evaluation shows that DAIL\\noutperforms the standard ICL method and other\\nensemble-based methods in the low-resource\\nscenario.', 'Additionally, we explore the use of\\nvoting consistency as a confidence score of the\\nmodel when the logits of predictions are inac-\\ncessible.', 'We believe our work will stimulate\\nfurther research on ICL in low-resource set-\\ntings.\\n', '1 Introduction\\nRecently, the rapid development of large language\\nmodels (LLMs) (Devlin et al., 2018; Radford et al.,\\n2019) and their striking skill and knowledge have\\nsparked significant interest in In-Context Learning\\n(ICL) (Brown et al., 2020).']\n",
      "Thoughts: ['It first utilizes the language model to generate paraphrases of the test sample and employs majority voting to determine the final result based on individual predictions.', 'Our extensive empirical evaluation shows that DAIL outperforms the standard ICL method and other ensemble-based methods in the low-resource scenario.', 'Additionally, we explore the use of voting consistency as a confidence score of the model when the logits of predictions are inaccessible.', 'We believe our work will stimulate further research on ICL in low-resource settings.', 'Recently, the rapid development of large language models (LLMs) and their striking skill and knowledge have sparked significant interest in In-Context Learning (ICL).']\n",
      "Passage: ['Different from other\\ntraining-based paradigms, under ICL, there is no\\nparameter adjustment to LLMs.', 'Instead, the model\\nis given an instruction, which usually consists of\\na task description (or prompt), several in-context\\nsamples (or demonstration), and the test case that\\nneeds to be inferred.', 'This tuning-free approach has\\ngained prominence in various research domains\\nwithin Natural Language Processing (NLP) due\\nto its impressive performance in numerous down-\\nstream tasks (Bonifacio et al., 2022; Gao et al.,\\n2023b,a).ICL requires demonstrations as part of the con-\\ntext.', 'Many works focus on improving ICL by em-\\nploying diverse methods to select suitable demon-\\nstrations, such as similarity-based retrieval (Liu\\net al., 2021; Rubin et al., 2021), score func-\\ntion learning (Li and Qiu, 2023), permutation\\nsearch (Lu et al., 2021; Wu et al., 2022), and etc.\\n', 'However, in numerous real-world scenarios, the\\navailability of annotated samples is severely con-\\nstrained (Mekala and Shang, 2020; Su et al., 2022)\\nfor such demonstration selection.']\n",
      "Thoughts: ['Different from other training-based paradigms, under ICL, there is no parameter adjustment to LLMs.', 'Instead, the model is given an instruction, which usually consists of a task description (or prompt), several in-context samples (or demonstration), and the test case that needs to be inferred.', 'This tuning-free approach has gained prominence in various research domains within Natural Language Processing (NLP) due to its impressive performance in numerous downstream tasks (Bonifacio et al., 2022; Gao et al., 2023b,a).', 'ICL requires demonstrations as part of the context.', 'Many works focus on improving ICL by employing diverse methods to select suitable demonstrations, such as similarity-based retrieval (Liu et al., 2021; Rubin et al., 2021), score function learning (Li and Qiu, 2023), permutation search (Lu et al., 2021; Wu et al., 2022), and etc.', 'However, in numerous real-world scenarios, the availability of annotated samples is severely constrained (Mekala and Shang, 2020; Su et al., 2022) for such demonstration selection.']\n",
      "Passage: ['Moreover, in the\\nfine-grained classification with a large target-label\\nspace, the context length of LLMs could not accom-\\nmodate more than one demonstration per label.\\n', 'To address these problems, we leverage the in-\\nsight of using the ensemble method and improve\\nICL for low-resource scenarios.', 'We propose Data\\nAugmentation for In-Context Learning ( DAIL )\\nthat uses the large language model paraphrase the\\ntest sample multiple times.', 'Subsequently, the para-\\nphrased samples, along with the original test sam-\\nple, are separately presented to the large language\\nmodel for inference.', 'Finally, a majority voting\\nmechanism is employed to integrate all the single\\nresults and get the final label.']\n",
      "Thoughts: ['LLMs could not accom-\\nmodate more than one demonstration per label.', 'To address these problems, we leverage the in-\\nsight of using the ensemble method and improve\\nICL for low-resource scenarios.', 'We propose Data\\nAugmentation for In-Context Learning ( DAIL )\\nthat uses the large language model paraphrase the\\ntest sample multiple times.', 'Subsequently, the para-\\nphrased samples, along with the original test sam-\\nple, are separately presented to the large language\\nmodel for inference.', 'Finally, a majority voting\\nmechanism is employed to integrate all the single\\nresults and get the final label.']\n"
     ]
    }
   ],
   "source": [
    "thoughts = read([sentence.text for sentence in doc.sents], limit=100)\n",
    "\n",
    "for chunk in batch(thoughts, bs=100):\n",
    "    store(*chunk, collection='tmp-basic-thoughts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we replace the instructions with something like:\n",
    "\n",
    "```\n",
    "You are an AI researcher reading a whitepaper.\n",
    "Given a passage of text from the paper, generate a list of thoughts about the passage.\n",
    "```\n",
    "\n",
    "This produces very similar results, but is now far less useful because of how specific it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, let's try to improve the results by providing some more context in each prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptx import prompt\n",
    "\n",
    "def read_with_recent_context(doc: list[str], bs=5, limit=None):\n",
    "    thoughts = []\n",
    "    recent_thoughts = []\n",
    "    previous_passage = None\n",
    "    for chunk in batch(doc, bs=bs, limit=limit):\n",
    "        print(f'Passage: {chunk}')\n",
    "        output = prompt(\n",
    "            '''\n",
    "            Given a passage from a document, generate a list of thoughts about the passage.\n",
    "            Don't repeat yourself!\n",
    "            ''',\n",
    "            input=dict(\n",
    "                passage=chunk,\n",
    "                previous_passage=previous_passage,\n",
    "                recent_thoughts=[t.value for t in recent_thoughts],\n",
    "            ),\n",
    "            output=[Thought],\n",
    "        ).objects\n",
    "\n",
    "        print(f'Thoughts: {[t.value for t in output]}')\n",
    "        thoughts += output\n",
    "        previous_passage = chunk\n",
    "        recent_thoughts = (output + recent_thoughts)[:5]\n",
    "    return thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage: ['DAIL:', 'Data Augmentation for In-Context Learning via Self-Paraphrase\\nDawei Li, Yaxuan Li, Dheeraj Mekala, Shuyao Li,\\nYulin wang, Xueqi Wang, William Hogan, Jingbo Shang\\nUniversity of California, San Diego\\ndal034, yal105, dmekala, shl118, yuw033\\nxuw030, whogan, jshang@ucsd.edu\\nAbstract\\nIn-Context Learning (ICL) combined with pre-\\ntrained large language models has achieved\\npromising results on various NLP tasks.', 'How-\\never, ICL requires high-quality annotated\\ndemonstrations which might not be available\\nin real-world scenarios.', 'To overcome this limi-\\ntation, we propose DataAugmentation for In-\\nContext Learning ( DAIL ).', 'DAIL leverages the\\nintuition that large language models are more\\nfamiliar with the content generated by them-\\nselves.']\n",
      "Thoughts: ['In-Context Learning (ICL) combined with pre-trained large language models has achieved promising results on various NLP tasks.', 'ICL requires high-quality annotated demonstrations which might not be available in real-world scenarios.', 'DataAugmentation for In-Context Learning (DAIL) is proposed to overcome this limitation.', 'DAIL leverages the intuition that large language models are more familiar with the content generated by themselves.']\n",
      "Passage: ['It first utilizes the language model to\\ngenerate paraphrases of the test sample and\\nemploys majority voting to determine the final\\nresult based on individual predictions.', 'Our ex-\\ntensive empirical evaluation shows that DAIL\\noutperforms the standard ICL method and other\\nensemble-based methods in the low-resource\\nscenario.', 'Additionally, we explore the use of\\nvoting consistency as a confidence score of the\\nmodel when the logits of predictions are inac-\\ncessible.', 'We believe our work will stimulate\\nfurther research on ICL in low-resource set-\\ntings.\\n', '1 Introduction\\nRecently, the rapid development of large language\\nmodels (LLMs) (Devlin et al., 2018; Radford et al.,\\n2019) and their striking skill and knowledge have\\nsparked significant interest in In-Context Learning\\n(ICL) (Brown et al., 2020).']\n",
      "Thoughts: ['The language model generates paraphrases of the test sample.', 'The final result is determined based on individual predictions through majority voting.', 'DAIL outperforms the standard ICL method and other ensemble-based methods in the low-resource scenario.', 'Voting consistency is explored as a confidence score when the logits of predictions are inaccessible.', 'The work on ICL in low-resource settings is expected to stimulate further research.']\n",
      "Passage: ['Different from other\\ntraining-based paradigms, under ICL, there is no\\nparameter adjustment to LLMs.', 'Instead, the model\\nis given an instruction, which usually consists of\\na task description (or prompt), several in-context\\nsamples (or demonstration), and the test case that\\nneeds to be inferred.', 'This tuning-free approach has\\ngained prominence in various research domains\\nwithin Natural Language Processing (NLP) due\\nto its impressive performance in numerous down-\\nstream tasks (Bonifacio et al., 2022; Gao et al.,\\n2023b,a).ICL requires demonstrations as part of the con-\\ntext.', 'Many works focus on improving ICL by em-\\nploying diverse methods to select suitable demon-\\nstrations, such as similarity-based retrieval (Liu\\net al., 2021; Rubin et al., 2021), score func-\\ntion learning (Li and Qiu, 2023), permutation\\nsearch (Lu et al., 2021; Wu et al., 2022), and etc.\\n', 'However, in numerous real-world scenarios, the\\navailability of annotated samples is severely con-\\nstrained (Mekala and Shang, 2020; Su et al., 2022)\\nfor such demonstration selection.']\n",
      "Thoughts: ['Under ICL, there is no parameter adjustment to LLMs.', 'The model is given an instruction, which usually consists of a task description, in-context samples, and a test case.', 'ICL has gained prominence in various research domains within NLP.', 'ICL requires demonstrations as part of the context.', 'Many works focus on improving ICL by employing diverse methods to select suitable demonstrations.', 'In numerous real-world scenarios, the availability of annotated samples is severely constrained for demonstration selection.', 'The language model generates paraphrases of the test sample.', 'The final result is determined based on individual predictions through majority voting.', 'DAIL outperforms the standard ICL method and other ensemble-based methods in the low-resource scenario.', 'Voting consistency is explored as a confidence score when the logits of predictions are inaccessible.', 'The work on ICL in low-resource settings is expected to stimulate further research.']\n",
      "Passage: ['Moreover, in the\\nfine-grained classification with a large target-label\\nspace, the context length of LLMs could not accom-\\nmodate more than one demonstration per label.\\n', 'To address these problems, we leverage the in-\\nsight of using the ensemble method and improve\\nICL for low-resource scenarios.', 'We propose Data\\nAugmentation for In-Context Learning ( DAIL )\\nthat uses the large language model paraphrase the\\ntest sample multiple times.', 'Subsequently, the para-\\nphrased samples, along with the original test sam-\\nple, are separately presented to the large language\\nmodel for inference.', 'Finally, a majority voting\\nmechanism is employed to integrate all the single\\nresults and get the final label.']\n",
      "Thoughts: ['LLMs could not accommodate more than one demonstration per label.', 'We leverage the insight of using the ensemble method and improve ICL for low-resource scenarios.', 'Data Augmentation for In-Context Learning (DAIL) uses the large language model to paraphrase the test sample multiple times.', 'The paraphrased samples, along with the original test sample, are separately presented to the large language model for inference.', 'A majority voting mechanism is employed to integrate all the single results and get the final label.', 'Under ICL, there is no parameter adjustment to LLMs.', 'The tuning-free approach of ICL has gained prominence in various research domains within Natural Language Processing (NLP).', 'Many works focus on improving ICL by employing diverse methods to select suitable demonstrations.', 'The availability of annotated samples is severely constrained for demonstration selection in numerous real-world scenarios.']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "thoughts = read_with_recent_context([sentence.text for sentence in doc.sents], limit=100)\n",
    "\n",
    "for chunk in batch(thoughts, bs=10):\n",
    "    store(*chunk, collection='tmp-recent-context-thoughts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptx import prompt, store, query, delete_collection\n",
    "\n",
    "def read_with_recalled_context(doc: list[str], bs=5, limit=None, collection='tmp'):\n",
    "    thoughts = []\n",
    "    recent_thoughts = []\n",
    "    previous_passage = None\n",
    "    try:\n",
    "        delete_collection(collection)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    for chunk in batch(doc, bs=bs, limit=limit):\n",
    "        print(f'Passage: {chunk}')\n",
    "        try:\n",
    "            recalled_thoughts = query(*chunk, limit=3, collection=collection).objects\n",
    "        except Exception as e:\n",
    "            print(f'Error querying {e}')\n",
    "            recalled_thoughts = []\n",
    "        output = prompt(\n",
    "            '''\n",
    "            Given a passage from a document, generate a list of thoughts about the passage.\n",
    "            Don't repeat yourself!\n",
    "            ''',\n",
    "            input=dict(\n",
    "                passage=chunk,\n",
    "                previous_passage=previous_passage,\n",
    "                recent_thoughts=[t.value for t in recent_thoughts],\n",
    "                recalled_thoughts=[t.value for t in recalled_thoughts],\n",
    "            ),\n",
    "            output=[Thought],\n",
    "        ).objects\n",
    "\n",
    "        print(f'Thoughts: {[t.value for t in output]}')\n",
    "        thoughts += output\n",
    "        previous_passage = chunk\n",
    "        recent_thoughts = (output + recent_thoughts)[:5]\n",
    "\n",
    "        quotes = [Quote(value=line) for line in chunk]\n",
    "        store(*output, *quotes, collection=collection)\n",
    "    return thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thoughts = read_with_recalled_context([sentence.text for sentence in doc.sents], limit=100)\n",
    "\n",
    "for chunk in batch(thoughts, bs=10):\n",
    "    store(*chunk, collection='tmp-recalled-context-thoughts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "No such keys(s): 'display.left_justify'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/rjl/promptx/examples/arxiv-reader/arxiv-reader.ipynb Cell 26\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/rjl/promptx/examples/arxiv-reader/arxiv-reader.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/rjl/promptx/examples/arxiv-reader/arxiv-reader.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m\"\u001b[39m\u001b[39mdisplay.max_colwidth\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/rjl/promptx/examples/arxiv-reader/arxiv-reader.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m pd\u001b[39m.\u001b[39;49mset_option(\u001b[39m'\u001b[39;49m\u001b[39mdisplay.left_justify\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/promptx/examples/arxiv-reader/venv-arxiv-reader/lib/python3.10/site-packages/pandas/_config/config.py:261\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__func__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/promptx/examples/arxiv-reader/venv-arxiv-reader/lib/python3.10/site-packages/pandas/_config/config.py:156\u001b[0m, in \u001b[0;36m_set_option\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_set_option() got an unexpected keyword argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkwarg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(args[::\u001b[39m2\u001b[39m], args[\u001b[39m1\u001b[39m::\u001b[39m2\u001b[39m]):\n\u001b[0;32m--> 156\u001b[0m     key \u001b[39m=\u001b[39m _get_single_key(k, silent)\n\u001b[1;32m    158\u001b[0m     o \u001b[39m=\u001b[39m _get_registered_option(key)\n\u001b[1;32m    159\u001b[0m     \u001b[39mif\u001b[39;00m o \u001b[39mand\u001b[39;00m o\u001b[39m.\u001b[39mvalidator:\n",
      "File \u001b[0;32m~/promptx/examples/arxiv-reader/venv-arxiv-reader/lib/python3.10/site-packages/pandas/_config/config.py:121\u001b[0m, in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m silent:\n\u001b[1;32m    120\u001b[0m         _warn_if_deprecated(pat)\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mraise\u001b[39;00m OptionError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such keys(s): \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(pat)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(keys) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    123\u001b[0m     \u001b[39mraise\u001b[39;00m OptionError(\u001b[39m\"\u001b[39m\u001b[39mPattern matched multiple keys\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOptionError\u001b[0m: No such keys(s): 'display.left_justify'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fb253487-4d5a-42e0-a89d-0d5f350e1011</td>\n",
       "      <td>quote</td>\n",
       "      <td>DAIL:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6e84618d-7f15-41bb-92be-e2c022d38d25</td>\n",
       "      <td>quote</td>\n",
       "      <td>Data Augmentation for In-Context Learning via Self-Paraphrase\\nDawei Li, Yaxuan Li, Dheeraj Mekala, Shuyao Li,\\nYulin wang, Xueqi Wang, William Hogan, Jingbo Shang\\nUniversity of California, San Diego\\ndal034, yal105, dmekala, shl118, yuw033\\nxuw030, whogan, jshang@ucsd.edu\\nAbstract\\nIn-Context Learning (ICL) combined with pre-\\ntrained large language models has achieved\\npromising results on various NLP tasks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a33b58f-f5b8-4be2-ae76-0c5a83d39b73</td>\n",
       "      <td>quote</td>\n",
       "      <td>How-\\never, ICL requires high-quality annotated\\ndemonstrations which might not be available\\nin real-world scenarios.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80454d13-9110-4e93-99e7-93d68e78b87b</td>\n",
       "      <td>quote</td>\n",
       "      <td>To overcome this limi-\\ntation, we propose DataAugmentation for In-\\nContext Learning ( DAIL ).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0b0754c5-5ca9-4645-a2ab-1834100fefad</td>\n",
       "      <td>quote</td>\n",
       "      <td>DAIL leverages the\\nintuition that large language models are more\\nfamiliar with the content generated by them-\\nselves.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>a38ea15f-9e00-4eb4-8d59-7e51a67987bc</td>\n",
       "      <td>quote</td>\n",
       "      <td>What type of information does the writer express for the question?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>61961fe1-6a7c-48ad-a2c7-24fcbd8e62f2</td>\n",
       "      <td>quote</td>\n",
       "      <td>EmotionLabel the emotion class of the sentence.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>64512d6c-0bea-4636-9c80-efd4c11a18d9</td>\n",
       "      <td>quote</td>\n",
       "      <td>What is the emotion expressed in this message?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>c2a9e0e0-0bab-466c-8f59-534f346db042</td>\n",
       "      <td>quote</td>\n",
       "      <td>What emotion does this message express?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>30105903-a5cf-4ce4-8283-d1fcca2592c4</td>\n",
       "      <td>quote</td>\n",
       "      <td>How will you feel about the message in terms of its emotion?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "                                       id   type  \\\n",
       "\u001b[1;36m0\u001b[0m    \u001b[93mfb253487-4d5a-42e0-a89d-0d5f350e1011\u001b[0m  quote   \n",
       "\u001b[1;36m1\u001b[0m    \u001b[93m6e84618d-7f15-41bb-92be-e2c022d38d25\u001b[0m  quote   \n",
       "\u001b[1;36m2\u001b[0m    \u001b[93m5a33b58f-f5b8-4be2-ae76-0c5a83d39b73\u001b[0m  quote   \n",
       "\u001b[1;36m3\u001b[0m    \u001b[93m80454d13-9110-4e93-99e7-93d68e78b87b\u001b[0m  quote   \n",
       "\u001b[1;36m4\u001b[0m    \u001b[93m0b0754c5-5ca9-4645-a2ab-1834100fefad\u001b[0m  quote   \n",
       "..                                    \u001b[33m...\u001b[0m    \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m225\u001b[0m  \u001b[93ma38ea15f-9e00-4eb4-8d59-7e51a67987bc\u001b[0m  quote   \n",
       "\u001b[1;36m226\u001b[0m  \u001b[93m61961fe1-6a7c-48ad-a2c7-24fcbd8e62f2\u001b[0m  quote   \n",
       "\u001b[1;36m227\u001b[0m  \u001b[93m64512d6c-0bea-4636-9c80-efd4c11a18d9\u001b[0m  quote   \n",
       "\u001b[1;36m228\u001b[0m  \u001b[93mc2a9e0e0-0bab-466c-8f59-534f346db042\u001b[0m  quote   \n",
       "\u001b[1;36m229\u001b[0m  \u001b[93m30105903-a5cf-4ce4-8283-d1fcca2592c4\u001b[0m  quote   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                               value\n",
       "\u001b[1;36m0\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                              DAIL:\n",
       "\u001b[1;36m1\u001b[0m    Data Augmentation for In-Context Learning via Self-Paraphrase\\nDawei Li, Yaxuan Li, Dheeraj Mekala, Shuyao Li,\\nYulin wang, Xueqi Wang, William Hogan, Jingbo Shang\\nUniversity of California, San Diego\\ndal034, yal105, dmekala, shl118, yuw033\\nxuw030, whogan, jshang@ucsd.edu\\nAbstract\\nIn-Context Learning \u001b[1m(\u001b[0mICL\u001b[1m)\u001b[0m combined with pre-\\ntrained large language models has achieved\\npromising results on various NLP tasks.\n",
       "\u001b[1;36m2\u001b[0m                                                                                                                                                                                                                                                                                                             How-\\never, ICL requires high-quality annotated\\ndemonstrations which might not be available\\nin real-world scenarios.\n",
       "\u001b[1;36m3\u001b[0m                                                                                                                                                                                                                                                                                                                                    To overcome this limi-\\ntation, we propose DataAugmentation for In-\\nContext Learning \u001b[1m(\u001b[0m DAIL \u001b[1m)\u001b[0m.\n",
       "\u001b[1;36m4\u001b[0m                                                                                                                                                                                                                                                                                                           DAIL leverages the\\nintuition that large language models are more\\nfamiliar with the content generated by them-\\nselves.\n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[33m...\u001b[0m\n",
       "\u001b[1;36m225\u001b[0m                                                                                                                                                                                                                                                                                                                                                             What type of information does the writer express for the question?\\n\n",
       "\u001b[1;36m226\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                EmotionLabel the emotion class of the sentence.\\n\n",
       "\u001b[1;36m227\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                 What is the emotion expressed in this message?\\n\n",
       "\u001b[1;36m228\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                        What emotion does this message express?\\n\n",
       "\u001b[1;36m229\u001b[0m                                                                                                                                                                                                                                                                                                                                                                   How will you feel about the message in terms of its emotion?\\n\n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m230\u001b[0m rows x \u001b[1;36m3\u001b[0m columns\u001b[1m]\u001b[0m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from promptx import prompt, store, query, delete_collection\n",
    "\n",
    "query(collection='tmp-quotes')[['id', 'type', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query('low rank', collection='tmp-quotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = query(collection='tmp-quotes')\n",
    "\n",
    "# use pandas methods to remove any rows with a 'value' column with a text length less than 10\n",
    "quotes = quotes[quotes['value'].str.len() > 25]\n",
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptx import prompt, query\n",
    "\n",
    "def rag_qa(question, collection='tmp', step_back=True):\n",
    "    if step_back:\n",
    "        intermediate_questions = prompt(\n",
    "            '''\n",
    "            Take a step back, and think of questions that would be helpful to answer the original question.\n",
    "            ''',\n",
    "            input=dict(\n",
    "                original_question=question,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        print(intermediate_questions)\n",
    "        intermediate_answers = rag_qa(intermediate_questions, collection=collection, step_back=False)\n",
    "    else:\n",
    "        intermediate_answers = None\n",
    "\n",
    "    print(intermediate_answers)\n",
    "    context = query(question, collection=collection).objects\n",
    "    print(context)\n",
    "    return prompt(\n",
    "        '''\n",
    "        Given a question and a context, generate an answer to the question.\n",
    "        ''',\n",
    "        input=dict(\n",
    "            question=question,\n",
    "            context=context,\n",
    "            ponderings=intermediate_answers\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I cannot generate an answer to the question as the input provided does not contain any relevant information or context. Please provide more information or a different question.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_qa('What is the title of the paper?', collection='tmp-quotes', step_back=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv-reader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
